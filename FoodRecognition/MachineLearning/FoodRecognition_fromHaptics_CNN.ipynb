{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1611390251924,
     "user": {
      "displayName": "Sota Tsubokura",
      "photoUrl": "",
      "userId": "13163055634424536761"
     },
     "user_tz": -540
    },
    "id": "kRi_AKqMV3t_",
    "outputId": "1e0c154c-89b0-458e-d0c4-d0366c30e588"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3635,
     "status": "ok",
     "timestamp": 1611400040203,
     "user": {
      "displayName": "Sota Tsubokura",
      "photoUrl": "",
      "userId": "13163055634424536761"
     },
     "user_tz": -540
    },
    "id": "sTGxR1UyV_EF",
    "outputId": "bfaf3d17-14ba-451d-9058-ab5dfd8be286"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3025,
     "status": "ok",
     "timestamp": 1611418968814,
     "user": {
      "displayName": "Sota Tsubokura",
      "photoUrl": "",
      "userId": "13163055634424536761"
     },
     "user_tz": -540
    },
    "id": "plDfMXecWATI",
    "outputId": "21a293b7-30ae-4216-8fba-3365df9a4414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4550, 400, 400, 1)\n",
      "(3412, 400, 400, 1)\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "# import keras\n",
    "# from keras.utils import np_utils\n",
    "# from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "# from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import pandas as pdl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "imgwide = 400\n",
    "imghigh = 400\n",
    "#imgdata_dir = \"/Users/sota/Labratory_Local/FoodRecognition/data/imgs\"#in local enviolenment, so must change\n",
    "imgdata_dir = \"/home/stsubokura/FoodRecognition/data/\"\n",
    "\n",
    "imgs = []\n",
    "label = []\n",
    "    \n",
    "folder = [\"cucumberinside_imgs\",\"cucumberoutside_imgs\"]\n",
    "image_size = 400\n",
    " \n",
    "for index, name in enumerate(folder):\n",
    "    dir = imgdata_dir + name\n",
    "    files = glob.glob(dir + \"/*.jpg\")\n",
    "    for i, file in enumerate(files):\n",
    "        image = Image.open(file)\n",
    "        image = image.convert(\"L\")\n",
    "        image = image.resize((image_size, image_size))\n",
    "        data = np.asarray(image)\n",
    "        data = data.reshape(image_size, image_size, 1)\n",
    "        imgs.append(data)\n",
    "        label.append(index)\n",
    "\n",
    "imgs = np.asarray(imgs)\n",
    "print(imgs.shape)\n",
    "imgs = imgs.astype('float32')\n",
    "imgs = imgs / 255.0\n",
    "\n",
    "label = np.asarray(label)\n",
    "label = tf.keras.utils.to_categorical(label, 7)\n",
    "\n",
    "# generate train and test data automatically, using scikit-learn\n",
    "# how diside random state size???\n",
    "img_train, img_test, label_train, label_test = train_test_split(imgs, label, test_size=0.25, random_state=111)\n",
    "print(img_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355338,
     "status": "ok",
     "timestamp": 1611419330161,
     "user": {
      "displayName": "Sota Tsubokura",
      "photoUrl": "",
      "userId": "13163055634424536761"
     },
     "user_tz": -540
    },
    "id": "NMB6AQAYcE7J",
    "outputId": "d8ab150c-fd65-4ba3-a8f5-6b37869fc322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "with tf.distribute.MirroredStrategy().scope():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=img_train.shape[1:]),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(7, activation='sigmoid' , kernel_regularizer = tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001) )\n",
    "    ])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# コンパイル\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 実行。\n",
    "history = model.fit(img_train, label_train, batch_size=256, epochs=epochs, validation_data=(img_test, label_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "executionInfo": {
     "elapsed": 2260,
     "status": "ok",
     "timestamp": 1611419350955,
     "user": {
      "displayName": "Sota Tsubokura",
      "photoUrl": "",
      "userId": "13163055634424536761"
     },
     "user_tz": -540
    },
    "id": "B7vSS07_xTg9",
    "outputId": "d0a43367-69fc-4ee4-c2ad-5fdfd201e65f"
   },
   "outputs": [],
   "source": [
    "plt.title('CNN ')\n",
    "plt.plot(range(1, epochs+1), history.history['accuracy'], label=\"training\")\n",
    "plt.plot(range(1, epochs+1), history.history['val_accuracy'], label=\"validation\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMHcKtflZou9YhVLvCcilEL",
   "collapsed_sections": [],
   "mount_file_id": "1O4SzjCRIG6n-DLUrIEk6MJsd9Lg4oDmT",
   "name": "FoodRecognition_fromHaptics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
